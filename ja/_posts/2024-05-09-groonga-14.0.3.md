---
layout: post.ja
title: Groonga 14.0.3リリース
description: Groonga 14.0.3をリリースしました！
---

## Groonga 14.0.3リリース

[Groonga 14.0.3](/ja/docs/news/14.html#release-14-0-3)をリリースしました！

それぞれの環境毎のインストール方法: [インストール](/ja/docs/install.html)

### 変更内容

主な変更点は以下の通りです。

### 改良

* 以下の最適化を行いました。

  * ヒット数が多いときの`OR`検索と`AND`検索のパフォーマンスを向上しました。
  * 前方一致検索(`@^`)のパフォーマンスを向上しました。
  * `A AND B`という条件で、BよりAのレコード数が多い場合のAND検索のパフォーマンスを向上しました。
  * 多くの動的カラムを設定している場合の検索パフォーマンスを向上しました。

* [TokenNgram](/ja/docs/reference/tokenizers/token_ngram.html) 新しいオプション`ignore_blank`を追加しました。

  以下のように`TokenBigramIgnoreBlank`を`TokenNgram("ignore_blank", true)`で置き換えることができます。

  `TokenBigram`を使う例です。

  ```
  tokenize TokenBigram "! ! !" NormalizerAuto
  [
    [
      0,
      1715155644.64263,
      0.001013517379760742
    ],
    [
      {
        "value": "!",
        "position": 0,
        "force_prefix": false,
        "force_prefix_search": false
      },
      {
        "value": "!",
        "position": 1,
        "force_prefix": false,
        "force_prefix_search": false
      },
      {
        "value": "!",
        "position": 2,
        "force_prefix": false,
        "force_prefix_search": false
      }
    ]
  ]
  ```

  `TokenBigramIgnoreBlank`を使う例です。

  ```
  tokenize TokenBigramIgnoreBlank "! ! !" NormalizerAuto
  [
    [
      0,
      1715155680.323451,
      0.0009913444519042969
    ],
    [
      {
        "value": "!!!",
        "position": 0,
        "force_prefix": false,
        "force_prefix_search": false
      }
    ]
  ]
  ```

  `TokenNgram("ignore_blank", true)`を使う例です。

  ```
  tokenize 'TokenNgram("ignore_blank", true)' "! ! !" NormalizerAuto
  [
    [
      0,
      1715155762.340685,
      0.001041412353515625
    ],
    [
      {
        "value": "!!!",
        "position": 0,
        "force_prefix": false,
        "force_prefix_search": false
      }
    ]
  ]
  ```

* [Ubuntu](/ja/docs/install/ubuntu.html) Ubuntu 24.04 LTS (Noble Numbat) をサポートしました。

### 修正

* [request_cancel](/ja/docs/reference/commands/request_cancel.html) `request_cancel`コマンドで実行中のクエリーを中断した時にGroongaがクラッシュすることがある問題を修正しました。

* `--post_filter`使用時に、`--offset`の値が`--post_filter`の結果より大きい場合に予期しないエラーになる問題を修正しました。

  `--filter`と`--offset`の組み合わせで、同様のケースになった場合はエラーは発生しません。`--filter`と`--post-filter`の挙動を合わせました。

  ```
  table_create Users TABLE_PAT_KEY ShortText
  column_create Users age COLUMN_SCALAR UInt32
  load --table Users
  [
    ["_key", "age"],
    ["Alice", 21],
    ["Bob", 22],
    ["Chris", 23],
    ["Diana", 24],
    ["Emily", 25]
  ]
  select Users \
    --filter 'age >= 22' \
    --post_filter 'age <= 24' \
    --offset 3 \
    --sort_keys -age --output_pretty yes
  [
    [
      -68,
      1715224057.317582,
      0.001833438873291016,
      "[table][sort] grn_output_range_normalize failed",
      [
        [
          "grn_table_sort",
          "/home/horimoto/Work/free-software/groonga.tag/lib/sort.c",
          1052
        ]
      ]
    ]
  ]
  ```

* 近傍フレーズ直積検索で`(...)`内のすべてのフレーズがマッチしない場合に、誤った検索結果を返す場合がある問題を修正しました。

  例えば以下の、`--query '*NPP1"(a) (2)"'`で指定している`(2)`にマッチするレコードはありません。この場合は、何もヒットしないのが正しい挙動ですが、
  `--query '*NPP1"(a)`相当の挙動になっていました。つまり、`(2)`にマッチするレコードが無いにも関わらず、`ax1`と`axx1`がヒットしていました。

  ```
  table_create Entries TABLE_NO_KEY
  column_create Entries content COLUMN_SCALAR Text

  table_create Terms TABLE_PAT_KEY ShortText   --default_tokenizer TokenNgram
  column_create Terms entries_content COLUMN_INDEX|WITH_POSITION Entries content
  load --table Entries
  [
  {"content": "ax1"},
  {"content": "axx1"}
  ]

  select Entries \
    --match_columns content \
    --query '*NPP1"(a) (2)"' \
    --output_columns 'content'
  [
    [
      0,
      1715224211.050228,
      0.001366376876831055
    ],
    [
      [
        [
          2
        ],
        [
          [
            "content",
            "Text"
          ]
        ],
        [
          "ax1"
        ],
        [
          "axx1"
        ]
      ]
    ]
  ]
  ```

* `TABLE_HASH_KEY`のテーブルに2^28以上のレコードが存在する時にリハッシュが発生すると、リハッシュが失敗するかテーブル内のデータが壊れる問題を修正しました。

* 以下のケースでハイライト位置がずれる問題を修正しました。

  * 以下のようにハイライト対象の文字の前に全角スペースがある場合。

    `"Groonga　<span class=\"keyword\">高</span>速！"`となることが期待値ですが、以下のように`"Groonga　<span class=\"keyword\">高速</span>！"`となっていました。

    ```
    table_create Entries TABLE_NO_KEY
    column_create Entries body COLUMN_SCALAR ShortText

    table_create Terms TABLE_PAT_KEY ShortText \
      --default_tokenizer 'TokenNgram("report_source_location", true)' \
      --normalizer 'NormalizerNFKC150("report_source_offset", true)'
    column_create Terms document_index COLUMN_INDEX|WITH_POSITION Entries body

    load --table Entries
    [
    {"body": "Groonga　高速！"}
    ]
    select Entries \
      --output_columns \
      --match_columns body \
      --query '高' \
      --output_columns 'highlight_html(body, Terms)'
    [
      [
        0,
        1715215640.979517,
        0.001608610153198242
      ],
      [
        [
          [
            1
          ],
          [
            [
              "highlight_html",
              null
            ]
          ],
          [
            "Groonga　<span class=\"keyword\">高速</span>！"
          ]
        ]
      ]
    ]
    ```

  * 以下のように`TokenNgram("loose_blank", true)`を使っていて、ハイライト対象の文字が全角スペースを含んでいる場合。

    `"<span class=\"keyword\">山田 太郎</span>"`となることが期待値ですが、以下のように`"<span class=\"keyword\">山田 太</span>"`となっていました。

    ```
    table_create Entries TABLE_NO_KEY
    column_create Entries body COLUMN_SCALAR ShortText

    table_create Terms TABLE_PAT_KEY ShortText \
      --default_tokenizer 'TokenNgram("loose_blank", true, "report_source_location", true)' \
      --normalizer 'NormalizerNFKC150("report_source_offset", true)'
    column_create Terms document_index COLUMN_INDEX|WITH_POSITION Entries body

    load --table Entries
    [
    {"body": "山田 太郎"}
    ]

    select Entries --output_columns \
      --match_columns body --query '山田太郎' \
      --output_columns 'highlight_html(body, Terms)' --output_pretty yes
    [
      [
        0,
        1715220409.096246,
        0.0004854202270507812
      ],
      [
        [
          [
            1
          ],
          [
            [
              "highlight_html",
              null
            ]
          ],
          [
            "<span class=\"keyword\">山田 太</span>"
          ]
        ]
      ]
    ]
    ```

    * 以下のようにハイライト対象の文字の先頭に空白スペースがある場合。

      `" <span class=\"keyword\">山</span>田太郎"`となることが期待値ですが、以下のように`" <span class=\"keyword\">山</span>"`となっていました。

      ```
      table_create Entries TABLE_NO_KEY
      column_create Entries body COLUMN_SCALAR ShortText

      table_create Terms TABLE_PAT_KEY ShortText \
        --default_tokenizer 'TokenNgram("report_source_location", true)' \
        --normalizer 'NormalizerNFKC150("report_source_offset", true)'
      column_create Terms document_index COLUMN_INDEX|WITH_POSITION Entries body

      load --table Entries
      [
      {"body": " 山田太郎"}
      ]

      select Entries \
        --output_columns \
        --match_columns body \
        --query '山' \
        --output_columns 'highlight_html(body, Terms)' --output_pretty yes
      [
        [
          0,
          1715221627.002193,
          0.001977920532226562
        ],
        [
          [
            [
              1
            ],
            [
              [
                "highlight_html",
                null
              ]
            ],
            [
              " <span class=\"keyword\">山</span>"
            ]
          ]
        ]
      ]
      ```

    * 以下のようにハイライト対象の２番めの文字が全角スペースの場合。

      `"<span class=\"keyword\">山　田</span>太郎"`となるのが期待値ですが、以下のように`"<span class=\"keyword\">山　田太</span>郎"`となっていました。

      ```
      table_create Entries TABLE_NO_KEY
      column_create Entries body COLUMN_SCALAR ShortText

      table_create Terms TABLE_PAT_KEY ShortText \
        --default_tokenizer 'TokenNgram("report_source_location", true)' \
        --normalizer 'NormalizerNFKC150("report_source_offset", true)'
      column_create Terms document_index COLUMN_INDEX|WITH_POSITION Entries body

      load --table Entries
      [
      {"body": "山　田太郎"}
      ]

      select Entries \
        --output_columns \
        --match_columns body \
        --query '山　田' \
        --output_columns 'highlight_html(body, Terms)'
      [
        [
          0,
          1715222501.496007,
          0.0005536079406738281
        ],
        [
          [
            [
              0
            ],
            [
              [
                "highlight_html",
                "<span class=\"keyword\">山　田太</span>郎"
              ]
            ]
          ]
        ]
      ]
      ```
